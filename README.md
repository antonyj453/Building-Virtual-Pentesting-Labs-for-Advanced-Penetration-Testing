# Building-Virtual-Pentesting-Labs-for-Advanced-Penetration-Testing
## Table of contents
* [Introducing Penetration Testing](#Introducing-Penetration-Testing)
* [Introduction to dlt](#Introduction-to-dlt)
* [Features](#Features)
* [Building data pipeline with dlt](#Building-data-pipeline-with-dlt)
* [First pipeline](#First-pipeline)

## Introducing Penetration Testing
In this chapter, we will discuss the role that pen testing plays in the professional
security testing framework. We will discuss the following topics:

* Define security testing
* An abstract security testing methodology
* Myths and misconceptions about pen testing

If you have been doing penetration testing for some time and are very familiar with
the methodology and concept of professional security testing, you can skip this
chapter, or just skim it, but you might learn something new or at least a different
approach to penetration testing.

#### Security testing
If you ask 10 consultants to define what security testing is today, you are more than
likely to get a variety of responses. If we refer to Wikipedia, their definition states:

"Security testing is a process to determine that an information system protects and
maintains functionality as intended."

In my opinion, this is the most important aspect of penetration testing. Security is
a process and not a product. I would also like to add that it is a methodology and
not a product.

Another component to add to our discussion is the point that security testing takes
into account the main areas of a security model; a sample of this is as follows:

* Authentication
* Authorization
* Confidentiality
* Integrity
* Availability
* Non-repudiation

Each one of these components has to be considered when an organization is in
the process of securing their environment. Each one of these areas in itself has
many subareas that also have to be considered when it comes to building a secure
architecture. The takeaway is that when we are testing security, we have to address
each of these areas.

#### Authentication
It is important to note that almost all systems and/or networks of today have some
form of authentication and as such this is usually the first area we secure. This could
be something as simple as users selecting a complex password or adding additional
factors to the authentication such as a token, biometric, or certificates. No single
factor of authentication is considered to be secure in today's networks.

#### Authorization
The concept of authorization is often overlooked as it is assumed and is not a
component of some security models. This is one approach to take, but it is preferred
to include it in most testing models. The concept of authorization is essential as it is
how we assign the rights and permissions to access a resource, and we would want
to ensure its security. Authorization allows us to have different types of users with
separate privilege levels to coexist within a system.

#### Confidentiality
The concept of confidentiality is the assurance that something we want to be
protected on the machine or network is safe and not at the risk of being compromised.
This is made harder by the fact that the protocol (TCP/IP) running the Internet today
was developed in the early 1970s. At that time, the Internet was used on just a few
computers, and now that the Internet has grown to the size it is today and as we are
still running the same protocol from those early days, it makes it more difficult to
preserve confidentiality.

It is important to note that when the developers created the protocol, the network was
very small and there was an inherent sense of trust with the person you potentially
could be communicating. This sense of trust is what we continue to fight from a
security standpoint today. The concept from that early creation was, and still is, that
you could trust data when it is received from a reliable source. We know that the
Internet is now of a huge size. However, this is definitely not the case.

#### Integrity
Integrity is similar to confidentiality. Here, we are concerned with the compromise of
the information and with the accuracy of the data and the fact that it is not modified
in transit or from its original form. A common way of doing this is to use a hashing
algorithm to validate that the file is unaltered.

#### Availability
One of the most difficult things to secure is the availability, that is, the right to have
a service when required. The irony about "availability" is that when a particular
resource is available to one user, then it is available to all. Everything seems perfect
from the perspective of an honest/legitimate user; however, not all users are honest/
legitimate due to the sheer fact that resources are finite and they can be flooded or
exhausted. Hence, it is all the more difficult to protect this area.

#### Non-repudiation
The non-repudiation statement makes the claim that a sender cannot deny sending
something; consequently, this is the one I usually have the most trouble with. We
know that a computer system can be and/or has been compromised many times and
also the art of spoofing is not a new concept. With these facts in our minds, the claim
that "we can guarantee the origin of a transmission by a particular person from a
particular computer" is not entirely accurate.

As we do not know the state of the machine, whether the machine is secure and not
compromised, this might be an accurate claim. However, to make this claim in the
networks that we have today would be a very difficult thing to do.
All it takes is one compromised machine and then the theory that "you can guarantee
the sender" goes out the window. We will not cover each of the components of security
testing in detail here because this is beyond the scope of what we are trying to achieve.
The point we want to get across in this section is that security testing is the concept of
looking at each and every component of security and addressing them by determining
the amount of risk an organization has from them and then mitigating that risk.

#### Abstract testing methodology
As mentioned previously, we concentrate on a process and apply that to our security
components when we go about security testing. For this, we describe an abstract
methodology here. We shall cover a number of methodologies and their components
in great detail in Chapter 4, Identifying Range Architecture, where we will identify a
methodology by exploring the available references for testing.
We will define our testing methodology, which consists of the following steps:
* Planning
* Nonintrusive target search
* Intrusive target search
* Data analysis
* Report
  
#### Planning
This is a crucial step for professional testing, but unfortunately, it is one of the
steps that is rarely given the time that is essentially required. There are a number of
reasons for this; however, the most common one is the budget. Clients do not want
to provide much time to a consultant to plan their testing. In fact, planning is usually
given a very small portion of the time in the contract due to this reason. Another
important point to note on planning is that a potential adversary will spend a lot of
time on it. There are two things that a tester should tell clients with respect to this
step, and that is there are two things that a professional tester cannot do that an
attacker can, and they are as follows:
* Six to nine months of planning
* Break the law
I could break the law I suppose and go to jail but it is not something that I find
appealing and as such am not going to do it. Additionally, being a certified hacker
and licensed penetration tester you are bound to an oath of ethics and I am not sure
but I believe that breaking the law while testing is a violation of this code of ethics.

#### Nonintrusive target search
There are many names that you will hear for nonintrusive target search. Some of
these are open source intelligence, public information search, and cyber intelligence.
Regardless of the name you use, they all come down to the same thing, that is,
using public resources to extract information about the target or company you are
researching. There are a plethora of tools that are available for this. We will briefly
discuss the following tools to get an idea of the concept and those who are not
familiar with them can try them out on their own:

* NsLookup:
The NsLookup tool is found as a standard program in the majority of the
operating systems we encounter. It is a method of querying DNS servers to
determine information about a potential target. It is very simple to use and
provides a great deal of information. Open a Command Prompt window on
your machine and enter nslookup www.packt.net. This will result in an
output similar to that shown in the following screenshot
![nslookup](https://github.com/antonyj453/DLT/assets/21340683/654cbc5e-24a1-4520-bc82-98d78e9ae9b5)

You can see in the preceding screenshot that the response to our command
is the IP address of the DNS server for the domain www.packt.net. You can
also see that their DNS has an IPv6 address configured. If we were testing
this site, we would explore this further. Alternatively, we may also use
another great DNS lookup tool called dig. For now, we will leave it alone
and move to the next resource.

* Serversniff:
The www.serversniff.net website has a number of tools that we can use
to gather information about a potential target. There are tools for IP, Crypto,
Nameserver, Webserver, and so on. An example of the home page for this
site is shown in the following screenshot:

![serversniff](https://github.com/antonyj453/DLT/assets/21340683/0f724c5b-b08d-43d1-a2e7-d2d332b940ae)

There are many tools we could show, but again we just want to briefly
introduce tools for each area of our security testing. Open a Command
Prompt window and enter tracert www.microsoft.com. In case you are
using Microsoft Windows OS, you will observe that the command fails, as
indicated in the following screenshot:

![tracert](https://github.com/antonyj453/DLT/assets/21340683/ccf4a9ac-f7bb-4248-b941-290cf1a25b42)

The majority of you reading this book probably know why this is blocked,
and for those of you who do not, it is because Microsoft has blocked the
ICMP protocol and this is what the tracert command uses by default. It is
simple to get past this because the server is running services and we can use
that particular protocol to reach it, and in this case, that protocol is TCP. Go
to the Serversniff page and navigate to IP Tools | TCP Traceroute. Then,
enter www.microsoft.com in the IP Address or Hostname box field and
conduct the traceroute. You will see it will now be successful, as shown in
the following screenshot:

![tcp-traceroute](https://github.com/antonyj453/DLT/assets/21340683/e76bf794-bbc5-45a3-a2ba-f18904395a25)

* Way Back Machine (www.archive.org):
This site is proof that anything that is ever on the Internet never leaves! There
have been many assessments when a client will inform the team that they are
testing a web server that is not placed into production, and when they are
shown that the site has already been copied and stored, they are amazed to
know that this actually does happen. I like to use the site to download some
of my favorite presentations, tools, and so on that have been removed from
a site and in some cases, the site no longer exists. As an example, one of the
tools that is used to show a student the concept of steganography is the tool
Infostego. This tool was released by Antiy Labs and it provided the student an
easy-to-use tool to understand the concepts. Well if you go to their site at www.
antiy.net, you will discover that there is no mention of the tool. In fact, it will
not be found in any of their pages. They now concentrate more on the antivirus
market. A portion from their page is shown in the following screenshot:

![Anity](https://github.com/antonyj453/DLT/assets/21340683/827a5bbe-f4d1-48f4-bed4-17069b0a9872)

Now let's use the power of the Way Back Machine to find our software.
Open a browser of your choice and enter www.archive.org. The Way
Back Machine is hosted here, and a sample of this site can be seen in the
following screenshot:

![wayback](https://github.com/antonyj453/DLT/assets/21340683/9d587a38-ffc7-4ec3-ae28-d522ce6f8a3a)

As indicated, there are 366 billion pages archived at the time this book was
written. In the URL section, enter www.antiy.net and click on Browse
History. This will result in the site searching its archives for the entered URL,
and after a few moments, the results of the search will be displayed. An
example of this is shown in the following screenshot:

![2013](https://github.com/antonyj453/DLT/assets/21340683/b3fe8ab5-3e23-4ae4-b7f8-ba01edf4a5db)

We know we do not want to access a page that has been recently archived,
so to be safe, click on 2008. This will result in the calendar being displayed,
showing all of the dates in 2008 the site was archived. You can select any one
that you want. An example of the archived site from December 18 is shown
in the following screenshot. As you can see, the Infostego tool is available and
you can even download it! Feel free to download and experiment with the
tool if you like.

![ghostbuster](https://github.com/antonyj453/DLT/assets/21340683/76df06cb-a988-4b79-bef4-8e912e85aa8a)

* Shodanhq:
The Shodan site is one of the most powerful cloud scanners we can use. You
are required to register with the site to be able to perform the more advanced
types of queries. It is highly recommended that you register at the site as
the power of the scanner and the information you can discover is quite
impressive, especially after the registration. The page that is presented
once you log in is shown in the following screenshot:

![shodan](https://github.com/antonyj453/DLT/assets/21340683/4e061f76-5403-48af-9341-310b8effc759)












